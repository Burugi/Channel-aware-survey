# configs/model/rnn.yaml
model_type: "rnn"

# Model Architecture
hidden_size: 64
num_layers: 4
nonlinearity: "relu"  # 'tanh' or 'relu'

# Training
dropout: 0.5

# Optimizer
optimizer:
  name: "Adam"
  params:
    lr: 0.0001
    weight_decay: 0.0001
    betas: [0.9, 0.999]
    eps: 1.0e-8

# Scheduler
scheduler:
  name: "ReduceLROnPlateau"
  params:
    mode: "min"
    factor: 0.5
    patience: 10
    min_lr: 1.0e-6
    verbose: true

# Loss
loss: "MSELoss"
loss_params: {}

#######################################################
#######################################################

## BASE configuration
## input 36 / prediction 24 / CD

# # configs/model/rnn.yaml
# model_type: "rnn"

# # Model Architecture
# hidden_size: 64
# num_layers: 4
# nonlinearity: "relu"  # 'tanh' or 'relu'

# # Training
# dropout: 0.5

# # Optimizer
# optimizer:
#   name: "Adam"
#   params:
#     lr: 0.0001
#     weight_decay: 0.0001
#     betas: [0.9, 0.999]
#     eps: 1.0e-8

# # Scheduler
# scheduler:
#   name: "ReduceLROnPlateau"
#   params:
#     mode: "min"
#     factor: 0.5
#     patience: 10
#     min_lr: 1.0e-6
#     verbose: true

# # Loss
# loss: "MSELoss"
# loss_params: {}

#######################################################
#######################################################

## BASE configuration
## input 36 / prediction 24 / CI

# # configs/model/rnn.yaml
# model_type: "rnn"

# # Model Architecture
# hidden_size: 64
# num_layers: 3
# nonlinearity: "relu"  # 'tanh' or 'relu'

# # Training
# dropout: 0.1

# # Optimizer
# optimizer:
#   name: "AdamW"
#   params:
#     lr: 0.005
#     weight_decay: 0.01
#     betas: [0.9, 0.999]
#     eps: 1.0e-8

# # Scheduler
# scheduler:
#   name: "ReduceLROnPlateau"
#   params:
#     mode: "min"
#     factor: 0.5
#     patience: 10
#     min_lr: 1.0e-6
#     verbose: true

# # Loss
# loss: "MSELoss"
# loss_params: {}